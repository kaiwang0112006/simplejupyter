{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用tensorflow的深度回归函数，像sklearn一样搭建自己的回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最近在研究tensorflow的使用，发现这个框架发展实在是快速，网上的例子可能很快由于版本更新而需要做调整。所以我也记录一下我搭建自己模型的过程。 整个过程主要参考了一个来自[kaggle帖子](https://www.kaggle.com/usersumit/allstate-claims-severity/tensorflow-dnnregressor)和一篇[QSAR文章](http://wikicoursenote.com/wiki/Deep_Neural_Nets_as_a_Method_for_Quantitative_Structure%E2%80%93Activity_Relationships)。\n",
    "\n",
    "因此数据来自kaggle竞赛，并做了一些神经网络参数的调整和丰富。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据来自[kaggle竞赛](https://www.kaggle.com/c/allstate-claims-severity), 关于保险公司对于各户数据的预测。包含类别特征(categorical feature)和数值特征(numerical feature). 我并没有过多的关注特征的含义，只是作为示例数据来构建神经网络。因此我只取了训练集的前5000行，既作为训练数据，也做测试数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9   ...        cont6  \\\n",
       "0   1    A    B    A    B    A    A    A    A    B   ...     0.718367   \n",
       "1   2    A    B    A    A    A    A    A    A    B   ...     0.438917   \n",
       "2   5    A    B    A    A    B    A    A    A    B   ...     0.289648   \n",
       "3  10    B    B    A    B    A    A    A    A    B   ...     0.440945   \n",
       "4  11    A    B    A    B    A    A    A    A    B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train_ori = pd.read_csv('train_head.csv')\n",
    "df_train_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (4999, 132)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data: %s\" % str(df_train_ori.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“cat”开头的数据为类别特征，将用独热编码(one-hot encoding)处理，“cont”开头的为数值特征，不用处理。最后将特征合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (4999, 849)\n"
     ]
    }
   ],
   "source": [
    "label = \"loss\"\n",
    "# drop id and fetch y.\n",
    "df_train_ori.drop('id', axis=1, inplace=True)\n",
    "y = df_train_ori[label]\n",
    "# one hot encode\n",
    "features = df_train_ori.columns\n",
    "continuous_features = [feature for feature in features if 'cont' in feature]\n",
    "categorical_features = [feature for feature in features if 'cat' in feature]\n",
    "one_hot = pd.get_dummies(df_train_ori[categorical_features])\n",
    "training_set = df_train_ori.drop(categorical_features, axis=1)\n",
    "training_set = training_set.join(one_hot)\n",
    "# re-fetch feature names\n",
    "features = [f for f in training_set.columns if f != label]\n",
    "print(\"Shape of data: %s\" % str(training_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征归一化也是预处理中重要的一步，sklearn中有非常方便高效的方法。最后数据矩阵化，就得到了可以最终的模型输入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# scale\n",
    "scaler = MinMaxScaler()\n",
    "training_set[features] = scaler.fit_transform(training_set[features])\n",
    "\n",
    "# matrix\n",
    "train_x = training_set[features].as_matrix()\n",
    "train_y = training_set[label].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 深度神经网络的结构，参数和训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我构建了一个三层的神经网络，定义了一个监控来实现提前终止(early stopping)。构建的函数为DNNRegressor，按照函数的输入要求，还需要定义特征列的对象，由于数据已经矩阵化没有特征名称信息，需要用下标来生成这个对象。对于回归问题，判断提前终止的量化标准为MSE，同时分出30%的数据来计算MSE判断是否提前终止。\n",
    "\n",
    "需要注意的是，如果想要模型下次再次重新载入，甚至投入生产，model_dir需要指定和保存好。同时ops也需要保存，下次用同样的参数构建DNNRegressor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 848), dtype=float64), required signatures: TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(None), Dimension(848)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=float64), required signatures: TensorSignature(dtype=tf.float64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNRegressor(hidden_units=[400, 200, 80], dropout=0.1, optimizer=<tensorflow.python.training.adagrad.AdagradOptimizer object at 0x7f968029bad0>, feature_columns=[_RealValuedColumn(column_name='', dimension=848, default_value=None, dtype=tf.float32, normalizer=None)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Feature cols\n",
    "feature_cols = [tf.contrib.layers.real_valued_column(\"\", dimension=len(features))]\n",
    "\n",
    "########################################################################\n",
    "# ------ PARAMETERS ---------\n",
    "training_validation_split = 0.8\n",
    "learning_rate             = 0.05           \n",
    "dropout                   = 0.1           \n",
    "network_structure         = [ 400, 200, 80 ]  \n",
    "early_stopping_rounds     = 100\n",
    "validate_every_n_steps    = 50\n",
    "max_steps                 = 290\n",
    "######################################################################\n",
    "\n",
    "######################################################################\n",
    "# ----- Split training and validation sets -----\n",
    "# ----- Create validation set for early stopping -----\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "\n",
    "validation_metrics = {'MSE': tf.contrib.metrics.streaming_mean_squared_error}\n",
    "val_monitor = tf.contrib.learn.monitors.ValidationMonitor(X_validate, y_validate,\n",
    "  every_n_steps=validate_every_n_steps,\n",
    "  metrics=validation_metrics,\n",
    "  early_stopping_metric=\"loss\",\n",
    "  early_stopping_metric_minimize=True,\n",
    "  early_stopping_rounds=early_stopping_rounds)\n",
    "######################################################################\n",
    "\n",
    "# Build 3 layer fully connected DNN \n",
    "ops = dict(feature_columns=feature_cols, \n",
    "          hidden_units=network_structure, \n",
    "          optimizer=tf.train.AdagradOptimizer(\n",
    "            learning_rate= learning_rate,\n",
    "          ),\n",
    "          model_dir=\"/tmp/test\",\n",
    "          dropout=dropout)\n",
    "\n",
    "regressor = tf.contrib.learn.DNNRegressor(**ops)\n",
    "\n",
    "# Training with Fit\n",
    "regressor.fit(X_train, y_train, steps=max_steps, monitors=[val_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方便起见，还用训练集来完成测试任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable=False is deprecated and will be removed after 2016-09-15.\n",
      "Instructions for updating:\n",
      "The default behavior of predict() is changing. The default value for\n",
      "as_iterable will change to True, and then the flag will be removed\n",
      "altogether. The behavior of this flag is described below.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score:             0.876760863552\n",
      "Explained Variance:    0.891644418607\n",
      "Median Absolute Error: 520.000625\n",
      "Mean Absolute Error:   725.465175455\n",
      "MAE Deviation:         745.977314795\n",
      "Mean Squared Error:    1082781.87499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "# predit\n",
    "y_test = y_train\n",
    "\n",
    "y_pred = regressor.predict(X_train, as_iterable=False)\n",
    "rmse = mean_squared_error(y_pred, y_test)\n",
    "\n",
    "# ---------- Score -------------\n",
    "r2Score     = metrics.r2_score(y_test, y_pred)\n",
    "exvarScore  = metrics.explained_variance_score(y_test, y_pred)\n",
    "medaeScore  = metrics.median_absolute_error(y_test, y_pred)\n",
    "maeScore    = metrics.mean_absolute_error(y_test, y_pred)\n",
    "maeDevScore = np.std(np.absolute(y_pred - y_test))\n",
    "mseScore    = metrics.mean_squared_error(y_test, y_pred)\n",
    " \n",
    "r2String       = 'R^2 Score:             {0}'.format(r2Score)\n",
    "varianceString = 'Explained Variance:    {0}'.format(exvarScore)\n",
    "medianString   = 'Median Absolute Error: {0}'.format(medaeScore)\n",
    "meanString     = 'Mean Absolute Error:   {0}'.format(maeScore)\n",
    "meanDevString  = 'MAE Deviation:         {0}'.format(maeDevScore)\n",
    "meanSqString   = 'Mean Squared Error:    {0}'.format(mseScore)\n",
    " \n",
    "print(r2String)\n",
    "print(varianceString)\n",
    "print(medianString)\n",
    "print(meanString)\n",
    "print(meanDevString)\n",
    "print(meanSqString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结\n",
    "\n",
    "tensorflow现在把skflow的函数转移到了tf.contrib.learn中，如DNNRegressor给习惯了使用sklearn的用户很好的体验tensorflow的一个起点。在训练过程中还可以通过tensorboard --logdir=/tmp/test 来进行监控。具体可以参考[官方文档](https://www.tensorflow.org/versions/r0.12/how_tos/summaries_and_tensorboard/index.html)。另外，记住以上的代码在tensorflow 0.11.0下完成，鉴于tensorflow现在每次更新都有较大调整，所以还是需要留意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
